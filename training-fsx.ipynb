{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9275057",
   "metadata": {},
   "source": [
    "## SageMaker training with FSx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed23fa2",
   "metadata": {},
   "source": [
    "This sample shows how to:\n",
    "\n",
    "- Setup FSx\n",
    "- Associate data in S3 with FSx\n",
    "- Run a SageMaker Training job using data from FSx mount\n",
    "- Save artifacts into FSx which are automatically pushed to S3\n",
    "- Tear down the infrastructure\n",
    "\n",
    "Checkout this [blog](https://aws.amazon.com/blogs/machine-learning/choose-the-best-data-source-for-your-amazon-sagemaker-training-job/) to verify if FSx is needed for your use-case to save operational costs. \n",
    "\n",
    "**Please make sure the CIDR block in setup/cfn-nlp.yaml does not conflict with your existing VPC. You can also change FSx storage (currently set at 1.2 TB) depending on your data sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "\n",
    "# Clients\n",
    "cfn_client = boto3.client(\"cloudformation\", region_name=region)\n",
    "fsx_client = boto3.client(\"fsx\", region_name=region)\n",
    "\n",
    "# Inputs\n",
    "region = \"us-east-1\"  # update this if your region is different\n",
    "region_az = \"us-east-1c\"  # customize this as needed. Your FSx will be set up in a subnet in this AZ\n",
    "cfn_stack_name = 'fsx-training'  # cloudformation stack name\n",
    "\n",
    "s3_data_bucket = 's3://sagemaker-us-east-1-988346548731'  # s3 bucket for training artifacts and datasets\n",
    "s3_data_train_prefix = 'train'  # s3 training data set\n",
    "s3_data_model_prefix = 'model_dir' # s3 path to save model\n",
    "s3_data_checkpoint_prefix = 'checkpoint_dir'  # s3 path to save model checkpoints\n",
    "fsx_file_system_path = 'fsx-train'  # this is file system path on FSx for the data, can be anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a6674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup infrastructure using CloudFormation\n",
    "with open(\"setup/cfn-nlp.yaml\", \"r\") as f:\n",
    "    template_body = f.read()\n",
    "    \n",
    "create_stack_response = cfn_client.create_stack(\n",
    "    StackName=cfn_stack_name,\n",
    "    TemplateBody=template_body,\n",
    "    Parameters=[\n",
    "        {\n",
    "            'ParameterKey': 'AZ',\n",
    "            'ParameterValue': region_az\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "create_stack_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5800b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wait for stack to be created, it takes ~10 minutes to complete.\n",
    "stack_id = create_stack_response['StackId']\n",
    "\n",
    "while True:\n",
    "    response = cfn_client.describe_stacks(\n",
    "        StackName=stack_id\n",
    "    )\n",
    "    status = response['Stacks'][0]['StackStatus']\n",
    "    if status== \"CREATE_IN_PROGRESS\":\n",
    "        print(\"Create in progress. Waiting..\")\n",
    "        time.sleep(30)\n",
    "    elif status==\"CREATE_COMPLETE\":\n",
    "        print(\"Stack created!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Error creating stack - check the CFN console\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stack outputs\n",
    "describe_response = cfn_client.describe_stacks(\n",
    "    StackName=stack_id\n",
    ")\n",
    "\n",
    "outputs = describe_response['Stacks'][0]['Outputs']\n",
    "\n",
    "for output in outputs:\n",
    "    if output['OutputKey'] == 'sg':\n",
    "        sec_group = output['OutputValue']\n",
    "    elif output['OutputKey'] == 'outputfsx':\n",
    "        fsx_id = output['OutputValue']\n",
    "    elif output['OutputKey'] == 'privatesubnet':\n",
    "        private_subnet_id = output['OutputValue']\n",
    "        \n",
    "fsx_response = fsx_client.describe_file_systems(\n",
    "    FileSystemIds=[fsx_id]\n",
    ")\n",
    "\n",
    "fsx_mount = fsx_response['FileSystems'][0]['LustreConfiguration']['MountName']\n",
    "\n",
    "print(\"FSx ID:\", fsx_id)\n",
    "print(\"Security Group ID:\", sec_group)\n",
    "print(\"Private Subnet ID:\", private_subnet_id)\n",
    "print(\"FSx Mount path:\", fsx_mount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data repository association with S3 to load data\n",
    "# and persist changes back to S3 to save training artifacts\n",
    "\n",
    "fsx_s3_response = fsx_client.create_data_repository_association(\n",
    "    FileSystemId=fsx_id,\n",
    "    FileSystemPath=f\"/{fsx_file_system_path}\",\n",
    "    DataRepositoryPath=s3_data_bucket,\n",
    "    BatchImportMetaDataOnCreate=True,\n",
    "    S3={\n",
    "        \"AutoImportPolicy\": {\n",
    "            \"Events\": ['NEW', 'CHANGED', 'DELETED']\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "fsx_s3_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46899a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wait for association to be complete\n",
    "while True:\n",
    "    fsx_s3_assoc = fsx_client.describe_data_repository_associations(\n",
    "        AssociationIds=[fsx_s3_response['Association']['AssociationId']]\n",
    "    )\n",
    "    fsx_status = fsx_s3_assoc['Associations'][0]['Lifecycle']\n",
    "\n",
    "    if fsx_status== \"CREATING\":\n",
    "        print(\"Create in progress. Waiting..\")\n",
    "        time.sleep(30)\n",
    "    elif fsx_status==\"AVAILABLE\":\n",
    "        print(\"FSx - S3 association complete!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Error creating the association, with status\", fx_status)\n",
    "        breaksec_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e592622",
   "metadata": {},
   "source": [
    "Now, we create a SageMaker training job that uses FSx as the training input. For detailed parameters for training job, see the [CreateTrainingJob API](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d3c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup fsx config for data channels\n",
    "fsx_directory_path = f\"/{fsx_mount}/{fsx_file_system_path}\"\n",
    "\n",
    "fsx_input = FileSystemInput(\n",
    "    file_system_id=fsx_id,\n",
    "    file_system_type='FSxLustre',\n",
    "    directory_path=fsx_directory_path,\n",
    "    file_system_access_mode=\"rw\", # write needed for saving model artifacts to fsx\n",
    ")\n",
    "data_channels = {\"train\": fsx_input}\n",
    "\n",
    "# for ease, so that you can use fsx for data and training artifacts\n",
    "SM_TRAIN_DIR = \"/opt/ml/input/data/train\"  # path where fsx is mounted in the training container\n",
    "hyperparameters = {}\n",
    "hyperparameters[\"checkpoint-dir\"] = f\"{SM_TRAIN_DIR}/{s3_data_checkpoint_prefix}\"\n",
    "hyperparameters[\"model-dir\"] = f\"{SM_TRAIN_DIR}/{s3_data_model_prefix}\"\n",
    "hyperparameters[\"training-dir\"] = f\"{SM_TRAIN_DIR}/{s3_data_train_prefix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f0e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setup estimator and invoke\n",
    "instance_type = \"ml.m5.xlarge\"\n",
    "instance_count = 1\n",
    "base_job_name = f'sagemaker-fsx-mount-sample'\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=os.getcwd(),\n",
    "    instance_type=instance_type,\n",
    "    role=get_execution_role(),\n",
    "    instance_count=instance_count,\n",
    "    framework_version=\"1.8.1\",\n",
    "    py_version=\"py36\",\n",
    "    checkpoint_s3_uri=None,  # as it is FSx\n",
    "    checkpoint_local_path=hyperparameters[\"checkpoint-dir\"],  # FSx\n",
    "    hyperparameters=hyperparameters,\n",
    "    base_job_name=base_job_name,\n",
    "    subnets = [private_subnet_id], # Give SageMaker Training Jobs access to FSx resources in your Amazon VPC\n",
    "    security_group_ids=[sec_group],\n",
    "    max_retry_attempts=30)\n",
    "\n",
    "estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3050cdd4",
   "metadata": {},
   "source": [
    "### Clean up resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ced56",
   "metadata": {},
   "source": [
    "You can tear down the CloudFormation stack to delete the VPC and associated resources, and the FSx file system to avoid incurring costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a3cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the stack\n",
    "\n",
    "delete_response = cfn_client.delete_stack(\n",
    "    StackName=stack_id\n",
    ")\n",
    "\n",
    "delete_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273547d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
